{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":9801,"sourceType":"datasetVersion","datasetId":6763}],"dockerImageVersionId":30627,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"from datasets import load_dataset\nimport pandas as pd\nimport nltk\nimport torch\nfrom nltk.corpus import stopwords\nfrom sklearn.metrics import average_precision_score\nfrom transformers import AutoTokenizer, AutoModel\nfrom sklearn.metrics.pairwise import cosine_similarity\nimport time\nimport numpy as np","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-01-06T17:48:36.954643Z","iopub.execute_input":"2024-01-06T17:48:36.955009Z","iopub.status.idle":"2024-01-06T17:48:36.960553Z","shell.execute_reply.started":"2024-01-06T17:48:36.954983Z","shell.execute_reply":"2024-01-06T17:48:36.959543Z"},"trusted":true},"execution_count":34,"outputs":[]},{"cell_type":"code","source":"# Check if GPU is available\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\n# Load the WikiQA dataset\ndataset = load_dataset(\"wiki_qa\")\ntrain_data = dataset['train']\nvalid_data = dataset['validation']\ntest_data = dataset['test']\n\n# Create DataFrames\ntrain_df = pd.DataFrame({'question': train_data['question'], 'document': train_data['document_title'], 'answer': train_data['answer'], 'label': train_data['label']})\nvalid_df = pd.DataFrame({'question': valid_data['question'], 'document': valid_data['document_title'], 'answer': valid_data['answer'], 'label': valid_data['label']})\ntest_df = pd.DataFrame({'question': test_data['question'], 'document': test_data['document_title'], 'answer': test_data['answer'], 'label': test_data['label']})\n\n# Display sample data\nprint(train_df.head())\nprint(valid_df.head())\nprint(test_df.head())","metadata":{"execution":{"iopub.status.busy":"2024-01-06T17:48:36.972577Z","iopub.execute_input":"2024-01-06T17:48:36.972863Z","iopub.status.idle":"2024-01-06T17:48:37.541784Z","shell.execute_reply.started":"2024-01-06T17:48:36.972837Z","shell.execute_reply":"2024-01-06T17:48:37.540574Z"},"trusted":true},"execution_count":35,"outputs":[{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/3 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6b6bf9c6b6874a82bec52d6073671efb"}},"metadata":{}},{"name":"stdout","text":"                        question      document  \\\n0  how are glacier caves formed?  Glacier cave   \n1  how are glacier caves formed?  Glacier cave   \n2  how are glacier caves formed?  Glacier cave   \n3  how are glacier caves formed?  Glacier cave   \n4  how are glacier caves formed?  Glacier cave   \n\n                                              answer  label  \n0  A partly submerged glacier cave on Perito More...      0  \n1          The ice facade is approximately 60 m high      0  \n2          Ice formations in the Titlis glacier cave      0  \n3  A glacier cave is a cave formed within the ice...      1  \n4  Glacier caves are often called ice caves , but...      0  \n                                      question          document  \\\n0  How are epithelial tissues joined together?  Tissue (biology)   \n1  How are epithelial tissues joined together?  Tissue (biology)   \n2  How are epithelial tissues joined together?  Tissue (biology)   \n3  How are epithelial tissues joined together?  Tissue (biology)   \n4  How are epithelial tissues joined together?  Tissue (biology)   \n\n                                              answer  label  \n0  Cross section of sclerenchyma fibers in plant ...      0  \n1  Microscopic view of a histologic specimen of h...      0  \n2  In Biology , Tissue is a cellular organization...      0  \n3  A tissue is an ensemble of similar cells from ...      0  \n4  Organs are then formed by the functional group...      0  \n                                          question  \\\n0  HOW AFRICAN AMERICANS WERE IMMIGRATED TO THE US   \n1  HOW AFRICAN AMERICANS WERE IMMIGRATED TO THE US   \n2  HOW AFRICAN AMERICANS WERE IMMIGRATED TO THE US   \n3  HOW AFRICAN AMERICANS WERE IMMIGRATED TO THE US   \n4  HOW AFRICAN AMERICANS WERE IMMIGRATED TO THE US   \n\n                                   document  \\\n0  African immigration to the United States   \n1  African immigration to the United States   \n2  African immigration to the United States   \n3  African immigration to the United States   \n4  African immigration to the United States   \n\n                                              answer  label  \n0  African immigration to the United States refer...      0  \n1  The term African in the scope of this article ...      0  \n2  From the Immigration and Nationality Act of 19...      0  \n3  African immigrants in the United States come f...      0  \n4  They include people from different national, l...      0  \n","output_type":"stream"}]},{"cell_type":"code","source":"# Text preprocessing\nnltk.download('stopwords')\nstop_words = set(stopwords.words('english'))\n\n# Load BERT tokenizer and model\ntokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\nmodel = AutoModel.from_pretrained(\"bert-base-uncased\")\nmodel.to(device)\n\n# Function to obtain BERT embeddings for a text\ndef get_bert_embedding(text, model=model, tokenizer=tokenizer, device=device):\n    inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, padding=True)\n    inputs = {key: value.to(device) for key, value in inputs.items()}\n    with torch.no_grad():\n        outputs = model(**inputs)\n    embeddings = outputs.last_hidden_state.mean(dim=1).squeeze().cpu().numpy()\n    return embeddings\n\n# Apply BERT embedding to the DataFrames\ntrain_df['question_embedding'] = train_df['question'].apply(lambda x: get_bert_embedding(x, model, tokenizer, device))\ntrain_df['document_embedding'] = train_df['document'].apply(lambda x: get_bert_embedding(x, model, tokenizer, device))\n\nvalid_df['question_embedding'] = valid_df['question'].apply(lambda x: get_bert_embedding(x, model, tokenizer, device))\nvalid_df['document_embedding'] = valid_df['document'].apply(lambda x: get_bert_embedding(x, model, tokenizer, device))\n\ntest_df['question_embedding'] = test_df['question'].apply(lambda x: get_bert_embedding(x, model, tokenizer, device))\ntest_df['document_embedding'] = test_df['document'].apply(lambda x: get_bert_embedding(x, model, tokenizer, device))\n\n# Display sample preprocessed data with BERT embeddings\nprint(train_df.head())\nprint(valid_df.head())\nprint(test_df.head())","metadata":{"execution":{"iopub.status.busy":"2024-01-06T17:48:37.543995Z","iopub.execute_input":"2024-01-06T17:48:37.544723Z","iopub.status.idle":"2024-01-06T18:00:27.528982Z","shell.execute_reply.started":"2024-01-06T17:48:37.544686Z","shell.execute_reply":"2024-01-06T18:00:27.527987Z"},"trusted":true},"execution_count":36,"outputs":[{"name":"stdout","text":"[nltk_data] Downloading package stopwords to /usr/share/nltk_data...\n[nltk_data]   Package stopwords is already up-to-date!\n                        question      document  \\\n0  how are glacier caves formed?  Glacier cave   \n1  how are glacier caves formed?  Glacier cave   \n2  how are glacier caves formed?  Glacier cave   \n3  how are glacier caves formed?  Glacier cave   \n4  how are glacier caves formed?  Glacier cave   \n\n                                              answer  label  \\\n0  A partly submerged glacier cave on Perito More...      0   \n1          The ice facade is approximately 60 m high      0   \n2          Ice formations in the Titlis glacier cave      0   \n3  A glacier cave is a cave formed within the ice...      1   \n4  Glacier caves are often called ice caves , but...      0   \n\n                                  question_embedding  \\\n0  [0.32571954, 0.11772122, 0.007693596, 0.038442...   \n1  [0.32571954, 0.11772122, 0.007693596, 0.038442...   \n2  [0.32571954, 0.11772122, 0.007693596, 0.038442...   \n3  [0.32571954, 0.11772122, 0.007693596, 0.038442...   \n4  [0.32571954, 0.11772122, 0.007693596, 0.038442...   \n\n                                  document_embedding  \n0  [0.23356321, 0.22610748, -0.158692, -0.1092391...  \n1  [0.23356321, 0.22610748, -0.158692, -0.1092391...  \n2  [0.23356321, 0.22610748, -0.158692, -0.1092391...  \n3  [0.23356321, 0.22610748, -0.158692, -0.1092391...  \n4  [0.23356321, 0.22610748, -0.158692, -0.1092391...  \n                                      question          document  \\\n0  How are epithelial tissues joined together?  Tissue (biology)   \n1  How are epithelial tissues joined together?  Tissue (biology)   \n2  How are epithelial tissues joined together?  Tissue (biology)   \n3  How are epithelial tissues joined together?  Tissue (biology)   \n4  How are epithelial tissues joined together?  Tissue (biology)   \n\n                                              answer  label  \\\n0  Cross section of sclerenchyma fibers in plant ...      0   \n1  Microscopic view of a histologic specimen of h...      0   \n2  In Biology , Tissue is a cellular organization...      0   \n3  A tissue is an ensemble of similar cells from ...      0   \n4  Organs are then formed by the functional group...      0   \n\n                                  question_embedding  \\\n0  [0.61421686, 0.044794116, 0.12983055, 0.086350...   \n1  [0.61421686, 0.044794116, 0.12983055, 0.086350...   \n2  [0.61421686, 0.044794116, 0.12983055, 0.086350...   \n3  [0.61421686, 0.044794116, 0.12983055, 0.086350...   \n4  [0.61421686, 0.044794116, 0.12983055, 0.086350...   \n\n                                  document_embedding  \n0  [0.10609293, -0.14742315, -0.42513114, -0.3123...  \n1  [0.10609293, -0.14742315, -0.42513114, -0.3123...  \n2  [0.10609293, -0.14742315, -0.42513114, -0.3123...  \n3  [0.10609293, -0.14742315, -0.42513114, -0.3123...  \n4  [0.10609293, -0.14742315, -0.42513114, -0.3123...  \n                                          question  \\\n0  HOW AFRICAN AMERICANS WERE IMMIGRATED TO THE US   \n1  HOW AFRICAN AMERICANS WERE IMMIGRATED TO THE US   \n2  HOW AFRICAN AMERICANS WERE IMMIGRATED TO THE US   \n3  HOW AFRICAN AMERICANS WERE IMMIGRATED TO THE US   \n4  HOW AFRICAN AMERICANS WERE IMMIGRATED TO THE US   \n\n                                   document  \\\n0  African immigration to the United States   \n1  African immigration to the United States   \n2  African immigration to the United States   \n3  African immigration to the United States   \n4  African immigration to the United States   \n\n                                              answer  label  \\\n0  African immigration to the United States refer...      0   \n1  The term African in the scope of this article ...      0   \n2  From the Immigration and Nationality Act of 19...      0   \n3  African immigrants in the United States come f...      0   \n4  They include people from different national, l...      0   \n\n                                  question_embedding  \\\n0  [0.23752125, -0.097810455, -0.44925365, -0.130...   \n1  [0.23752125, -0.097810455, -0.44925365, -0.130...   \n2  [0.23752125, -0.097810455, -0.44925365, -0.130...   \n3  [0.23752125, -0.097810455, -0.44925365, -0.130...   \n4  [0.23752125, -0.097810455, -0.44925365, -0.130...   \n\n                                  document_embedding  \n0  [0.020983413, 0.21801582, -0.45750546, -0.0389...  \n1  [0.020983413, 0.21801582, -0.45750546, -0.0389...  \n2  [0.020983413, 0.21801582, -0.45750546, -0.0389...  \n3  [0.020983413, 0.21801582, -0.45750546, -0.0389...  \n4  [0.020983413, 0.21801582, -0.45750546, -0.0389...  \n","output_type":"stream"}]},{"cell_type":"code","source":"# Function to perform semantic search on a query using cosine similarity with BERT embeddings\ndef semantic_search_bert(query_embedding, document_embeddings):\n    similarities = cosine_similarity([query_embedding], document_embeddings)[0]\n    return similarities\n\n# Perform semantic search for 100 queries using BERT embeddings\nnum_queries = 100\nmap_scores = []\nelapsed_times = []\n\nfor i in range(num_queries):\n    # Randomly select a query from the test set\n    query_row = test_df.sample(1).iloc[0]\n    query_embedding = get_bert_embedding(query_row['question'])\n    \n    # Perform semantic search and measure time elapsed\n    start_time = time.time()\n    predictions = semantic_search_bert(query_embedding, np.vstack(test_df['document_embedding'].values))\n    elapsed_time = time.time() - start_time\n    \n    # Calculate MAP for the query\n    true_labels = test_df['label'].values\n    map_score = average_precision_score(true_labels, predictions)\n    \n    # Append results to lists\n    map_scores.append(map_score)\n    elapsed_times.append(elapsed_time)\n\n# Calculate average MAP and average time elapsed\naverage_map = np.mean(map_scores)\naverage_time_elapsed = np.mean(elapsed_times)\n\n# Display results\nprint(f\"Average MAP for {num_queries} queries: {average_map}\")\nprint(f\"Average time elapsed for each query: {average_time_elapsed} seconds\")","metadata":{"execution":{"iopub.status.busy":"2024-01-06T18:00:27.530357Z","iopub.execute_input":"2024-01-06T18:00:27.530748Z","iopub.status.idle":"2024-01-06T18:00:35.511393Z","shell.execute_reply.started":"2024-01-06T18:00:27.530713Z","shell.execute_reply":"2024-01-06T18:00:35.510154Z"},"trusted":true},"execution_count":37,"outputs":[{"name":"stdout","text":"Average MAP for 100 queries: 0.05074964931327312\nAverage time elapsed for each query: 0.048799877166748044 seconds\n","output_type":"stream"}]}]}